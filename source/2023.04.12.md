# Visualization Tools for Big Data

## Introduction
In my previous article, I barely touched the concept of Visualization Tools. The front-end is a critical part of your data pipeline since it is the visible part of your analytical platform; no matter how good your data pipeline is, it needs reliable and performant visualization tools to achieve it purpose: provide meaningful insights so stakeholders can make important data-driven decisions.

In this article I will give a quick overview of the different visualization options available for your processed data after running your data pipeline. I will focus on open source solutions which are a cheaper and more portable option. Public Cloud Providers have several options for BI and data visualization which I recommend that you explore but it will be out of the scope for this article. In general, using these cloud services is very easy and straightforward but it is more expensive than using an open source solution.

Some comercial solutions that you may consider are Qlik, Looker or Tableau, these are also outside the scope of this article.

### Visualization Options
Depending on your use case, you can think of two broad categories for visualization:

- BI Tools: In this category you have tools used internally in your organization to meet your analytical needs for different stake holders such business users, data scientist, engineers and manager. These tools may be used in on-prem deployment or in cloud. Al thought access can be granted to customers, they tend to be used by your company and not to expose analytics to your users.
- Visualization Tools: In this category we have tools focused on creating front end applications for visualization. These include charting libraries and analytical APIs for the front end applications. These tools are mainly used to integrate with existing products such the customer facing web site.

In a nutshell, think of BI tools mainly as internal analytical tools, multi tenant all-in-one solutions; in the other hand, think of Visualization Tools mainly as customer-facing, front-end, usually single tenant and single purpose solutions. Let’s review some of them!

### BI Tools
In this section we will review some of the solutions that provide the following:

- Ability to connect to many data sources
- Visualization: dashboards and charts
- Query builders
- Reports and Alerts

### SuperSet
SuperSet is the most popular Open Source BI Tool for visualization. It is based on Python and it can query data from any SQL-speaking datastore or data engine (like Presto or AWS Athena) that has a Python DB-API driver and a SQLAlchemy dialect.

It supports a wide range of charts for visualization and you can also create rich dashboards. It also has an interface to run ad-hoc queries. It is very easy to use and the performance is great. Users can configure automated alerts and reports to send to an email recipient or Slack channel:

- Alerts are sent when a SQL condition is reached
- Reports are sent on a schedule

These are the main features according to their documentation:

- An intuitive interface for visualizing datasets and crafting interactive dashboards
- A wide array of beautiful visualizations to showcase your data
- Code-free visualization builder to extract and present datasets
- A world-class SQL IDE for preparing data for visualization, including a rich metadata browser
- A lightweight semantic layer which empowers data analysts to quickly define custom dimensions and metrics
- Out-of-the-box support for most SQL-speaking databases
- Seamless, in-memory asynchronous caching and queries
- An extensible security model that allows configuration of very intricate rules on who can access which product features and datasets.
- Integration with major authentication backends (database, OpenID, LDAP, OAuth, REMOTE_USER, etc)
- The ability to add custom visualization plugins
- An API for programmatic customization
- A cloud-native architecture designed from the ground up for scale

It is relatively easy to get started with Docker. It has many configuration options and it supports in-memory cache using Redis. If you require any special visualization which is not supported out of the box, you can create your own.

SuperSet is feature rich, popular, has great support and it is easy to use. It supports a huge number of databases including Cloud DBs, traditional DBs and NoSQL data stores. It also works well with services like NewRelic, StatsD and DataDog.

Superset is currently running at scale at many companies such as AirBnB.

### Metabase
Metabase is an alternative to Superset which is easier to setup and has similar features:

- Rich beautiful dashboards with auto refresh and full-screen
- SQL Mode for analysts and data pros
- Create canonical segments and metrics for your team to use
- Send data to Slack or email on a schedule with dashboard subscriptions
- Alerts and reports.

It also supports many databases either officially or by the community. The cool thing is that it has enterprise support if required and even a very easy to use cloud offering.

What I like about Metabase is that you don’t need to be a BI expert to use it. It has a very simple and easy to use query builder and many visualizations; you can create dashboards very quickly and easily share them. Follow this simple guide to get started.

### Querybook
Querybook is an open source big data IDE/notebook. It is a bit different than the previous tools since its main goal is to help you analyse, document and share your analytical queries and visualizations. It is similar to Jupyter Notebook but focused on Big Data.

It uses the concept of DataDoc using cells that can contain documentation or a query. This way you can create notebooks describing your queries and visualizations. When writing a query the smart editor is aware of your data sources and provides auto completion, syntax highlighting and much more.

It provides charts such as line, bar, stacked area, pie, horizontal bar, donut, scatter, and tables. So you can document, query and visualize the data in one place. It also has a great templating engine to keep your queries DRY.

You can refresh your notebook data using a scheduler to keep the data up to date. Querybook can also send scheduled updates to external apps.

Finally, Querybook auto analyzes executed queries to provide data lineage, example queries, frequent user information, search/auto-completion ranking.

It is very easy to get started using Docker. It also support many data sources, meta stores, authentication providers and has integrations to many cloud providers to export query results to S3 or GCS.

Querybook target audience differs a bit from the other tools since it is more focused on data analysis and discover; intended mainly for data scientists and data analysts.

### Visualization Tools
In this section, our focus is the use case when you want to provide your users with analytics, usually by embedding charts, widgets and other data into your existing product. In this case you need an API to manage the queries and a UI framework.

You can implement your own API to serve your front-end application, but this requires a lot of work, specially for Big Data. You don’t want to query your database directly for two main reasons:

- Your database may change, this why we use APIs. Also, it is more than likely that you have multiple databases which adds to the complexity.
- You will need to do a lot of performance optimization to be able to produce responsible charts and dashboards.
It is recommended that you use an API that provides the following:

- A friendly Semantic API to build dashboards that abstracts the underlying data store and exposes an standard BI schema in terms of measures, dimensions, segments, etc; hiding the underlying complexity or implementation details. Remember that you may be querying different types of databases such as SQL or NoSQL.
- A in-memory cache.
- Multi-tenant support. So you can query data for different customers/users in a safe manner.
- Query Optimization.
- Pre-aggregations such as roll-ups for complex aggregations.
- Authentication support, for example, using JWT tokens.

Many OLAP Engines like Druid provide REST APIs so you can query the data from the UI, but even in this case, it is recommended to have another level of abstraction if you have multiple data sources, need authentication, etc. So, unless you are committed to only one data source, consider having an extra layer. SuperSet and Metabase already do this, they provide an API and visualization in one single tool.

In this section, we will focus on the use case where you want to own the front-end application, so you will need an Analytical API. For this use case, I recommend Cube.js, let’s have a look…

### Cube.js
Cube.js is an open-source Analytical API platform that makes accessing your raw data very easy and performant; it does not provide visualizations but it has many templates, modules and examples to get your started very quickly. This is by design, so you can choose the library of your choice and integrate with any front-end framework or charting library.

You just need follow 3 simple steps:

- Install Cube.js. It can run anywhere: Kubernetes, Serverless, on-prem, etc.
- Connect to the data sources. It supports many different types of data sources, from Serverless Cloud Data Warehouses to traditional RDBMs. You can connect to many sources.
- Build your front-end. Cube.js can generate a Dashboard App for you to get your started, then you can customize it as you please and integrate it with your product/website.

That’s it!, Cube.js handles the rest.

It provides all the features we mentioned above and it is very easy to get started. You can also use Cube.js as your internal Analytical API, specially if you require your own front-end application.

In short, Cube.js is the answer to the question: Okay, I have the perfect data pipeline and valuable data stored somewhere, how can use it and get value from it?

Cube.js adds a Semantic API layer on top of your data to speed up the development of your visualizations; Cube.js also manages access control, cache, and aggregate data. It can work with Serverless data warehouses such as Google BigQuery and AWS Athena. Since Cube.js is visualization agnostic, you can use any frontend library to build your own custom UI.

Cube.js provides the necessary infrastructure for any analytics application that heavily relies on a caching and a pre-aggregation layer to provide insights from raw data within minutes and an API with sub-second response times on up to a trillion data points. This would be very hard to achieve if you had to implement it on your own. Check theses examples to get a feeling of the Cube.js capabilities and exceptional features.

#### Architecture

Cube.js acts as an analytics backend, translating business logic (metrics and dimensions) into SQL on top of managing caching, queuing and database connection.

The Cube.js client sends queries conforming to the Query Format to the REST API. The server uses a Schema to generate an SQL query, which is executed by your chosen database. The server handles all the database connections, as well as pre-aggregations and caching layers. The result is then sent back to the client. The client itself is visualization-agnostic and works well with any chart library.

Cube.js provides the backend required to access all your data sources in an efficient manner and a front-end client to query this data in a secure manner from your website or mobile apps. On top of that, it has templates and libraries to help you build the front-end regardless of the framework you use (React, Angular, Vue…) or the charting library that you want to use.

Now that you have your API and your front-end client with Cube.js, the fina piece is deciding which charting library to use.

Let’s review some of the options…

### Charting Libraries
Deciding about which library you should use is crucial, you don’t want slow responses or browser tabs crashing while visualizing the data. This last task, the UI, is the last step of your data pipeline journey, and and arguably the most important one; getting this right is very important if you want to avoid user frustration and eventually project failure.

You should consider the following:

- The size of your data. Some libraries are better at handle large datasets than others.
- The types of visualizations you want to use. Some libraries are more feature rich that others.
- Low level vs high level abstractions. Low level libraries will give you more control and usually better performance but there are harder to use and it will take more time to develop.
- Mobile App Support. Some libraries are easier to integrate with native mobile apps than others. Also, some libraries are more responsive than others.
- SVG vs. Canvas. Some libraries are based on SVG and other in Canvas. SVG has lower memory footprint and better performance which makes it a great option for mobile, but since SVG is part of the DOM, it may struggle handling big datasets, for this case Canvas is a better option. Some libraries provide support for both render options.

I recommend doing spikes and testing some of the libraries and compare them side by side before making a decision. There are a huge number of libraries available, in this article I will just give a quick overview of my favorites. You can find more libraries and options in this article created by the Cube.js team. I will focus on open source libraries only.

### Chart.js
This is the most popular library, it easy to use and has enough charts to get you started, it is a good option to introduce yourself into this word. It is responsive, uses HTML5 canvas and it is open source; the problem is that it only has 8 types of charts.


### Recharts
This is a great option if you are building your front-end with React. It is a high level wrapper around D3 library, abstracting the complexity of the D3 low level API and making it super easy to integrate with your React application by exposing simple React components. It supports themes and it is easy to customize.

This is the best library to get started with React.

### Nivo
Nivo is another React wrapper around D3. It has a lot more charts than Recharts and support both SVG and Canvas. It supports themes and it is easy to customize.

### D3
This is probably the most famous charting library for data visualization. It is very flexible, performant, has many charts and it is highly customizable.

The downsize is that it is difficult to use and you need expertise in the team to take advantage of the low level features that it provides. Also, it will take more time to develop the charts.

### ECharts
Apache ECharts is another open-source library, it has a lot of charts, great performance and it is relative easy to use. It is highly customizable and has good documentation.

It uses a high performant render engine called zrender which provides many optimizations. The cool thing is that you can select at runtime if you want to use SVG or Canvas to render your charts. This is a great features because with the same code you can switch between the engine depending on the data size or platform.

It is easy to integrate with any UI Framework and has a great community behind it. Many companies are using it in production environments. It performs as well as D3 but is easier to use. For example, SuperSet is now moving to ECharts.

In summary, I recommend Chart.js or Recharts to get your started and ECharts for more complex visualizations.

### Conclusion
I’ve talked a lot about Big Data, but one mistake I tend to do and so many engineers, is forgetting about the front-end. This is critical, this is how users interact with the data and mine the value stored in the source databases.

You need to select the best tool for the job based on your use case. If you just need a BI Tool, choose any from the comercial available or deploy one of the powerful open source tools such SuperSet or Metabase which will be cheaper to run and adapt to your needs. For data exploration, discovery and analysis consider QueryBook. If you heavily rely on your cloud provider, check their offerings as well.

We’ve also discussed the option of customer-facing analytics and the possibility of embedding analytical queries and visualizations in your website or product instead of using a all-in-one BI solution. For this case, we talked about the need of abstraction layer with an Analytical API and we used Cube.js as an example. This abstraction allows us to connect to many data sources in an efficient and secure manner while keeping the API UI framework agnostic so you can use the same stack that you use on your product.

Finally, for the UI we reviewed some of my favorite charting libraries, we mentioned that Chart.js is great to start with for Vanilla JS and ReCharts for React but I really like the power and capabilities of ECharts.

Remember to clap if you enjoyed this article and follow me or subscribe for more updates!

Subscribe to get notified when I publish an article and Join Medium.com to access millions or articles!
